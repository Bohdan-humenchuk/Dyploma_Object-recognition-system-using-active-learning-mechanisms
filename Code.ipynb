{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For correct work, you need to download dataset from kaggle and unpack in the same directory with code. \n",
    "#### Link: [https://www.kaggle.com/dmitryyemelyanov/chinese-traffic-signs](https://www.kaggle.com/dmitryyemelyanov/chinese-traffic-signs)\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
    "import tqdm\n",
    "import time \n",
    "import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from skimage import io\n",
    "from skimage import transform as transform_image\n",
    "import skimage\n",
    "#from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset \n",
    "#### output - number of rows in data pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2242\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('annotations.csv', delimiter=',')\n",
    "data = raw_data[raw_data.category < 16][raw_data.category != 9].reset_index(drop = True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset class to reorganize data in torchvision format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChRoadSighnDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, annotation, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = annotation\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])\n",
    "        image = skimage.io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 7]\n",
    "        landmarks = np.array([landmarks])\n",
    "        ##landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating transformation classes to transform the input data into tensor format of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size\"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        img = transform_image.resize(image, (self.output_size, self.output_size))\n",
    "\n",
    "        return {'image': img, 'landmarks': landmarks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        images = torch.from_numpy(image) \n",
    "        labels = torch.from_numpy(landmarks)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining of the neural network structure class \n",
    "#### __init__ - creating convolution/neural layers \n",
    "#### forward - defining order of layers and direction of data flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.fc1 = nn.Linear(64*32*32, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised learning section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the sampling function for first learning method \n",
    "#### It devides data on two parts: train and test pools \n",
    "#### We have 2 types of sampling: static and random \n",
    "#### For training purposes, it's better to use random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_sampling(data): \n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "    \n",
    "    percentage_for_train_set = 0.8 ## in range 0-1\n",
    "    percentage_for_test_set = 0.2 ## in range 0-1\n",
    "    \n",
    "    for class_num in set(data[\"category\"]):\n",
    "        data_preroll = data[data.category == class_num]\n",
    "        sampled_class_train = data_preroll.iloc[: round(len(data_preroll)*percentage_for_train_set) ,:]\n",
    "        train_data = pd.concat([sampled_class_train, train_data]) \n",
    "        sampled_class_test = data_preroll.iloc[round(len(data_preroll)*percentage_for_test_set) : ,:]\n",
    "        test_data = pd.concat([sampled_class_test, test_data])\n",
    "    \n",
    "    return train_data.reset_index(drop = True), test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(data): #normal fully random sampling\n",
    "    from random import randint\n",
    "    \n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    for class_num in set(data[\"category\"]):\n",
    "        sampled_class_train = data[data.category == class_num].sample(frac = 0.8, random_state = randint(0, 200))\n",
    "        train_data = pd.concat([sampled_class_train, train_data])\n",
    "        sampled_class_test = data[data.category == class_num].sample(frac = 0.2, random_state = randint(0, 200))\n",
    "        test_data = pd.concat([sampled_class_test, test_data])\n",
    "    return train_data.reset_index(drop = True), test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reorganizing to torchvision DataLoader format\n",
    "#### It connects every image to corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([Rescale(128), ToTensor()])\n",
    "train_data, test_data = random_sampling(data)\n",
    "print(len(train_data), len(test_data))\n",
    "\n",
    "trainset = ChRoadSighnDataset(annotation = train_data, root_dir = 'images/', transform = transform)\n",
    "testset = ChRoadSighnDataset(annotation = test_data, root_dir = 'images/', transform = transform)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = {0 : 'sp_lim_5', 1 : 'sp_lim_15', 2 : 'sp_lim_30', 3 : 'sp_lim_40', 4 : 'sp_lim_50', 5 : 'sp_lim_60',\n",
    "           6 : 'sp_lim_70', 7 : 'sp_lim_80', 8 : 'no_move_left_front', 10 : 'no_move_front', 11: 'no_move_left',\n",
    "           12: 'no_move_left_right', 13: 'no_move_right', 14: 'no_outdrive', 15: 'no_reversal'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_p = Net()\n",
    "loss_func_p = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_p.parameters(), lr=0.01, momentum=0.9)\n",
    "clock_p = []\n",
    "\n",
    "epoch_num = 5\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epoch_num)):  # loop over the dataset multiple times\n",
    "    tic_av = time.perf_counter()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(trainloader, 0):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        images = torch.tensor(images, dtype=torch.float32)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net_p(images)\n",
    "        labels = labels.squeeze(1)\n",
    "        #print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    #tqdm.tqdm.write('[%d, %5d] loss: %.5f' % (epoch + 1, i + 1, running_loss / 2200))\n",
    "    loss_func_p.append(running_loss/1793)\n",
    "    toc_av = time.perf_counter()\n",
    "    clock_p.append(toc_av - tic_av)\n",
    "toc = time.perf_counter()\n",
    "print('Finished Training in', toc-tic, \"seconds, meaning\", str(datetime.timedelta(seconds = toc-tic))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './net_passive_trained.pth'\n",
    "torch.save(net_p.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic, testing and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print(loss_func_p)\n",
    "## print(len(loss_func_p))\n",
    "\n",
    "## print(clock_p)\n",
    "## print(sum(clock_p)/len(clock_p))\n",
    "\n",
    "fig, axes = plt.subplots() \n",
    "axes.plot(loss_func_p) \n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')\n",
    "axes.set_title(\"Loss per 50 epoch\")\n",
    "\n",
    "fig, axes = plt.subplots() \n",
    "axes.plot(clock_p) \n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Execution time')\n",
    "axes.set_title(\"Learning time per epoch of learning, seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in tqdm.tqdm(testloader):\n",
    "        images, labels = data\n",
    "        images = torch.tensor(images, dtype=torch.float32)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net_p(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        #print(predicted == labels)\n",
    "        correct += ((predicted == labels).sum().item())\n",
    "\n",
    "#print(total)\n",
    "#print(correct)\n",
    "print('Accuracy of the network on the 449 test images: %d %%' % (100 * correct/5 / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active learning section "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining sampling functions. init_sampling is used for creating first training pool. Next iterations of data pool creation are using active_sampling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sampling(data): \n",
    "    train_data = pd.DataFrame()\n",
    "    train_data = data.sample(n = 1000, random_state = randint(0, 200))\n",
    "    return train_data.reset_index(drop = True), data.reset_index(drop = True)\n",
    "\n",
    "def active_sampling(data): \n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "    for class_num in set(data[\"category\"]):\n",
    "        data_preroll = data[data.category == class_num]\n",
    "        sampled_class_train = data_preroll.iloc[: round(len(data_preroll)*0.8) ,:] \n",
    "        test_data = data\n",
    "    train_data = data.sample(n = 200, random_state = randint(0, 200))\n",
    "    return train_data.reset_index(drop = True), test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning with active learning algorithm \n",
    "\n",
    "##init network and learning algorithm \n",
    "net_a = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_p.parameters(), lr=0.01, momentum=0.9) \n",
    "\n",
    "##init vars and arrays \n",
    "batch_size = 10\n",
    "clock_a = []\n",
    "loss_func_a = []\n",
    "raw_data = pd.read_csv('annotations.csv', delimiter=',')\n",
    "data = raw_data[raw_data.category < 16][raw_data.category != 9].reset_index(drop = True)\n",
    "\n",
    "##starting whole training process, main timer start\n",
    "tic_av = time.perf_counter()\n",
    "\n",
    "##init dataset and dataloader \n",
    "transform = torchvision.transforms.Compose([Rescale(128), ToTensor()])\n",
    "init_data, _ = init_sampling(data)\n",
    "init_set = ChRoadSighnDataset(annotation = init_data, root_dir = 'images/', transform = transform)\n",
    "init_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=0) #init_sampling(data)\n",
    "\n",
    "##initial pre-training\n",
    "running_loss = 0.0\n",
    "for i, (images, labels) in enumerate(init_loader, 0): \n",
    "    optimizer.zero_grad()\n",
    "    images = torch.tensor(images, dtype=torch.float32)\n",
    "\n",
    "    outputs = net_a(images)\n",
    "    labels = labels.squeeze(1)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item() \n",
    "    \n",
    "\n",
    "##save and print statistics \n",
    "toc_av = time.perf_counter() \n",
    "loss_func_a.append(running_loss/200)\n",
    "clock_a.append(toc_av-tic_av)\n",
    "\n",
    "print(\"network initialized\")\n",
    "print(\"loss: \", loss_func_a)\n",
    "print(\"time: \", toc_av-tic_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm.tqdm(range(20)):\n",
    "    \n",
    "    tic_av = time.perf_counter()\n",
    "    \n",
    "    next_epoch_loader, _ = active_sampling(data)\n",
    "    active_set = ChRoadSighnDataset(annotation = init_data, root_dir = 'images/', transform = transform)\n",
    "    active_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(active_loader, 0): \n",
    "        optimizer.zero_grad()\n",
    "        images = torch.tensor(images, dtype=torch.float32)\n",
    "\n",
    "        outputs = net_a(images)\n",
    "        labels = labels.squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    toc_av = time.perf_counter()   \n",
    "    loss_func_a.append(running_loss/200)\n",
    "    clock_a.append(toc_av-tic_av)\n",
    "\n",
    "\n",
    "print('Finished Training in ', sum(clock_a), \" seconds, or\", str(datetime.timedelta(seconds = toc-tic))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './net_active_trained.pth'\n",
    "torch.save(net_a.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic, testing and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(loss_func_a)\n",
    "#print(len(loss_func_a))\n",
    "\n",
    "#print(clock_a)\n",
    "#print(sum(clock_a)/len(clock_a))\n",
    "\n",
    "fig, axes = plt.subplots() \n",
    "axes.plot(loss_func_a) \n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')\n",
    "axes.set_title(\"Loss per 50 epoch\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots() \n",
    "axes.plot(clock_a) \n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Execution time')\n",
    "axes.set_title(\"Learning time per epoch of learning, seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
